{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install support packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input, decode_predictions\n",
    "from tensorflow.keras.applications.vgg19 import VGG19, preprocess_input, decode_predictions\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, CSVLogger\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_curve, confusion_matrix\n",
    "\n",
    "import cv2\n",
    "\n",
    "import scikitplot as skplt\n",
    "\n",
    "import os, sys, glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dir(path):\n",
    "    if os.path.exists(path):\n",
    "        print(\"Dir already exist\")\n",
    "    \n",
    "    elif sys.platform == 'win32':\n",
    "        os.system('mkdir ' + path)\n",
    "    \n",
    "    else:\n",
    "        os.system('mkdir -p ' + path)\n",
    "        print('New Path created : ', path)\n",
    "    return \n",
    "    \n",
    "# Define the routine the add a new last layer\n",
    "def add_new_last_layer(base_model, nb_classes):\n",
    "    print('Add last layer to the convnet..')\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(nb_classes, activation='relu')(x)  # new FC layer, random init\n",
    "    predictions = Dense(nb_classes, activation='softmax')(x)  # new softmax layer\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)  # Combine the network\n",
    "    return model\n",
    "\n",
    "def get_im(path):\n",
    "    # Load as grayscale\n",
    "    img = cv2.imread(path, 0)\n",
    "    # Reduce size\n",
    "    resized = cv2.resize(img, (224, 224))\n",
    "    return resized\n",
    "\n",
    "def load_train():\n",
    "    nb_classes = 2\n",
    "    img_rows, img_cols = 224, 224\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "\n",
    "    path='/tf/data/data_OCT/dme/*.png'\n",
    "    files = glob.glob(path)\n",
    "    for fl in files:\n",
    "        img = get_im(fl)\n",
    "        X_train.append(img)\n",
    "        y_train.append(1)\n",
    "\n",
    "    path='/tf/data/data_OCT/normal/*.png'\n",
    "    files = glob.glob(path)\n",
    "    for fl in files:\n",
    "        img = get_im(fl)\n",
    "        X_train.append(img)\n",
    "        y_train.append(0)\n",
    "\n",
    "    X_train = np.array(X_train, dtype=np.uint8)\n",
    "    y_train = np.array(y_train, dtype=np.uint8)\n",
    "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "    # train_data = train_data.transpose((0, 3, 1, 2))\n",
    "    y_train = to_categorical(y_train, nb_classes)\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_train /= 255\n",
    "    print('Train shape:', X_train.shape)\n",
    "    print(X_train.shape[0], 'train samples')\n",
    "\n",
    "    return X_train, y_train\n",
    "\n",
    "def split_validation_set(train, target, test_size):\n",
    "    random_state = 51\n",
    "    X_train, X_test, y_train, y_test = train_test_split(train, target, test_size=test_size, random_state=random_state)\n",
    "    print('Split train: ', len(X_train))\n",
    "    print('Split valid: ', len(X_test))\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare tensorboard\n",
    "TB_LOG = './output/logs_tb'\n",
    "check_dir(TB_LOG)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=TB_LOG,\n",
    "                          histogram_freq=0,\n",
    "                          batch_size=32,\n",
    "                          write_graph=True,\n",
    "                          write_grads=False,\n",
    "                          write_images=False,\n",
    "                          embeddings_freq=0,\n",
    "                          embeddings_layer_names=None,\n",
    "                          embeddings_metadata=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, Y_train, \n",
    "                    batch_size=32, \n",
    "                    epochs=5, \n",
    "                    verbose=1, \n",
    "                    validation_data=(X_test, Y_test))\n",
    "\n",
    "# Save model\n",
    "model.save('./output/my_model.h5') \n",
    "del model  # clear memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained model\n",
    "model = load_model('./output/my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "Y_pred=model.predict([X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance report\n",
    "target_names = [\"normal\", \"dme\"]\n",
    "print(classification_report(np.argmax(Y_test, axis=1), np.argmax(Y_pred, axis=1), target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot roc curve\n",
    "skplt.metrics.plot_roc_curve(np.argmax(Y_test,axis=1), Y_pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show confusion matrix\n",
    "confusion_matrix(np.argmax(Y_test,axis=1), np.argmax(Y_pred,axis=1))\n",
    "model.metric()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restart kernel"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
